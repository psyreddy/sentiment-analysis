{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    " The data set consists of `train.csv` and `test.csv` files which consistes of `tweet_id`,`entity`,`sentiment`,`tweet content`. The data set contained 4 classes of sentiments but we are performing binary classification, so the data was preprocesses accordingly. Data set used is available in [Kaggle](https://www.kaggle.com/datasets/jp797498e/twitter-entity-sentiment-analysis)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data Preprocessing\n",
    "- The Preprocessed training data contains `tweet_id`, `sentiment`, and `tweet`.\n",
    "- The preprocessed data is saved into `./dataset/train-processed.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved processed tweets to: dataset/train-processed.csv\n"
     ]
    }
   ],
   "source": [
    "!python3 src/preprocess.py --filename='dataset/train.csv' --is_train=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data Preprocessing\n",
    "- The Preprocessed testing data contains `tweet_id` and `tweet`.\n",
    "- The preprocessed data is saved into `./dataset/test-processed.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved processed tweets to: dataset/test-processed.csv\n"
     ]
    }
   ],
   "source": [
    "!python3 src/preprocess.py --filename='dataset/test.csv' --is_train=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics of train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 43374/43374\n",
      "Calculating frequency distribution\n",
      "Saved uni-frequency distribution to ./dataset/train-processed-freqdist.pkl\n",
      "Saved bi-frequency distribution to ./dataset/train-processed-freqdist-bi.pkl\n",
      "\n",
      "[Analysis Statistics]\n",
      "Tweets => Total: 43374, Positive: 20832, Negative: 22542\n",
      "User Mentions => Total: 11313, Avg: 0.2608, Max: 17\n",
      "URLs => Total: 484, Avg: 0.0112, Max: 1\n",
      "Emojis => Total: 367, Positive: 210, Negative: 157, Avg: 0.0085, Max: 1\n",
      "Words => Total: 736150, Unique: 19415, Avg: 16.9721, Max: 166, Min: 0\n",
      "Bigrams => Total: 693107, Unique: 175684, Avg: 15.9798\n"
     ]
    }
   ],
   "source": [
    "!python3 src/stats.py './dataset/train-processed.csv' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct = 68.97%\n"
     ]
    }
   ],
   "source": [
    "!python3 src/baseline.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating feature vectors\n",
      "Processing 43374/43374\n",
      "\n",
      "Extracting features & training batches\n",
      "Processing 1/1\n",
      "\n",
      "Testing\n",
      "Processing 1/1\n",
      "Correct: 3910/4338 = 90.1337 %\n"
     ]
    }
   ],
   "source": [
    "!python3 src/naivebayes.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating feature vectors\n",
      "Processing 43374/43374\n",
      "\n",
      "Extracting features & training batches\n",
      "Iteration 79/79, loss:0.6893, acc:0.0600\n",
      "Epoch: 1, val_acc:0.8142\n",
      "Accuracy improved from 0.0000 to 0.8142, saving model\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "Iteration 79/79, loss:0.6885, acc:0.0620\n",
      "Epoch: 2, val_acc:0.8313\n",
      "Accuracy improved from 0.8142 to 0.8313, saving model\n",
      "Iteration 79/79, loss:0.6880, acc:0.0580\n",
      "Epoch: 3, val_acc:0.8444\n",
      "Accuracy improved from 0.8313 to 0.8444, saving model\n",
      "Iteration 79/79, loss:0.6840, acc:0.0600\n",
      "Epoch: 4, val_acc:0.8527\n",
      "Accuracy improved from 0.8444 to 0.8527, saving model\n",
      "Iteration 79/79, loss:0.6832, acc:0.0600\n",
      "Epoch: 5, val_acc:0.8615\n",
      "Accuracy improved from 0.8527 to 0.8615, saving model\n",
      "Iteration 79/79, loss:0.6744, acc:0.0720\n",
      "Epoch: 6, val_acc:0.8665\n",
      "Accuracy improved from 0.8615 to 0.8665, saving model\n",
      "Iteration 79/79, loss:0.6768, acc:0.0700\n",
      "Epoch: 7, val_acc:0.8704\n",
      "Accuracy improved from 0.8665 to 0.8704, saving model\n",
      "Iteration 79/79, loss:0.6811, acc:0.0620\n",
      "Epoch: 8, val_acc:0.8757\n",
      "Accuracy improved from 0.8704 to 0.8757, saving model\n",
      "Iteration 79/79, loss:0.6697, acc:0.0680\n",
      "Epoch: 9, val_acc:0.8804\n",
      "Accuracy improved from 0.8757 to 0.8804, saving model\n",
      "Iteration 79/79, loss:0.6827, acc:0.0580\n",
      "Epoch: 10, val_acc:0.8829\n",
      "Accuracy improved from 0.8804 to 0.8829, saving model\n",
      "Iteration 79/79, loss:0.6696, acc:0.0700\n",
      "Epoch: 11, val_acc:0.8889\n",
      "Accuracy improved from 0.8829 to 0.8889, saving model\n",
      "Iteration 79/79, loss:0.6755, acc:0.0600\n",
      "Epoch: 12, val_acc:0.8907\n",
      "Accuracy improved from 0.8889 to 0.8907, saving model\n",
      "Iteration 79/79, loss:0.6660, acc:0.0680\n",
      "Epoch: 13, val_acc:0.8926\n",
      "Accuracy improved from 0.8907 to 0.8926, saving model\n",
      "Iteration 79/79, loss:0.6682, acc:0.0640\n",
      "Epoch: 14, val_acc:0.8949\n",
      "Accuracy improved from 0.8926 to 0.8949, saving model\n",
      "Iteration 79/79, loss:0.6690, acc:0.0640\n",
      "Epoch: 15, val_acc:0.9373\n",
      "Accuracy improved from 0.8949 to 0.9373, saving model\n",
      "Iteration 79/79, loss:0.6585, acc:1.0000\n",
      "Epoch: 16, val_acc:0.9394\n",
      "Accuracy improved from 0.9373 to 0.9394, saving model\n",
      "Iteration 79/79, loss:0.6546, acc:0.9980\n",
      "Epoch: 17, val_acc:0.9414\n",
      "Accuracy improved from 0.9394 to 0.9414, saving model\n",
      "Iteration 79/79, loss:0.6614, acc:0.9940\n",
      "Epoch: 18, val_acc:0.9444\n",
      "Accuracy improved from 0.9414 to 0.9444, saving model\n",
      "Iteration 79/79, loss:0.6562, acc:0.9920\n",
      "Epoch: 19, val_acc:0.9451\n",
      "Accuracy improved from 0.9444 to 0.9451, saving model\n",
      "Iteration 79/79, loss:0.6567, acc:0.9960\n",
      "Epoch: 20, val_acc:0.9461\n",
      "Accuracy improved from 0.9451 to 0.9461, saving model\n",
      "Testing\n",
      "Generating feature vectors\n",
      "Processing 543/543\n",
      "\n",
      "Predicting batches\n",
      "Processing 2/2\n",
      "Saved to logistic.csv\n"
     ]
    }
   ],
   "source": [
    "!python3 src/logistic.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK MaxEnt model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (1 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.480\n",
      "         Final          -0.57272        0.838\n",
      "  -1.778 dirty==True and label is '1'\n",
      "  -1.197 goat==True and label is '1'\n",
      "  -1.005 lovely==True and label is '0'\n",
      "   1.000 necessity==True and label is '1'\n",
      "   1.000 yy==True and label is '1'\n",
      "   1.000 fuu==True and label is '0'\n",
      "   1.000 stfallol==True and label is '0'\n",
      "   1.000 weakening==True and label is '1'\n",
      "   1.000 fuuh==True and label is '0'\n",
      "   1.000 dammn==True and label is '0'\n",
      "Validation set accuracy:0.8137\n",
      "\n",
      "Predicting for test data\n",
      "\n",
      "Saved to maxent.csv\n"
     ]
    }
   ],
   "source": [
    "!python3 src/maxent-nltk.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating feature vectors\n",
      "Processing 43374/43374\n",
      "\n",
      "Extracting features & training batches\n",
      "Processing 1/1\n",
      "\n",
      "Testing\n",
      "Processing 1/1\n",
      "Correct: 3231/4338 = 74.4813 %\n"
     ]
    }
   ],
   "source": [
    "!python3 src/decisiontree.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating feature vectors\n",
      "Processing 43374/43374\n",
      "\n",
      "Extracting features & training batches\n",
      "Processing 1/1\n",
      "\n",
      "Testing\n",
      "Processing 1/1\n",
      "Correct: 4113/4338 = 94.8133 %\n"
     ]
    }
   ],
   "source": [
    "!python3 src/randomforest.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating feature vectors\n",
      "Processing 43374/43374\n",
      "\n",
      "Extracting features & training batches\n",
      "Processing 1/1\n",
      "\n",
      "Testing\n",
      "Generating feature vectors\n",
      "Processing 543/543\n",
      "\n",
      "Predicting batches\n",
      "Processing 2/1\n",
      "Saved to xgboost.csv\n"
     ]
    }
   ],
   "source": [
    "!python3 src/xgboost_classifier.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating feature vectors\n",
      "Processing 43374/43374\n",
      "\n",
      "Extracting features & training batches\n",
      "Processing 1/1/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "Testing\n",
      "Processing 1/1\n",
      "Correct: 3947/4338 = 90.9866 %\n"
     ]
    }
   ],
   "source": [
    "!python3 src/svm.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating feature vectors\n",
      "Processing 43374/43374\n",
      "\n",
      "Extracting features & training batches\n",
      "Iteration 79/79, loss:0.7108, acc:0.0660\n",
      "Epoch: 1, val_acc:0.8732\n",
      "Accuracy improved from 0.0000 to 0.8732, saving model\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "Iteration 79/79, loss:0.7133, acc:0.0660\n",
      "Epoch: 2, val_acc:0.9119\n",
      "Accuracy improved from 0.8732 to 0.9119, saving model\n",
      "Iteration 79/79, loss:0.6848, acc:0.0640\n",
      "Epoch: 3, val_acc:0.9262\n",
      "Accuracy improved from 0.9119 to 0.9262, saving model\n",
      "Iteration 79/79, loss:0.6643, acc:0.9880\n",
      "Epoch: 4, val_acc:0.9357\n",
      "Accuracy improved from 0.9262 to 0.9357, saving model\n",
      "Iteration 79/79, loss:0.6041, acc:0.9960\n",
      "Epoch: 5, val_acc:0.9398\n",
      "Accuracy improved from 0.9357 to 0.9398, saving model\n",
      "Testing\n",
      "Generating feature vectors\n",
      "Processing 543/543\n",
      "\n",
      "Predicting batches\n",
      "Processing 2/2\n",
      "Saved to 1layerneuralnet.csv\n"
     ]
    }
   ],
   "source": [
    "!python3 src/neuralnet.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reccurent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for GLOVE vectors\n",
      "Processing 1193514/0essing 401644/0cessing 681166/0cessing 801185/0cessing 924603/0cessing 968400/0495/0388/0\n",
      "\n",
      "Found 14671 words in GLOVE\n",
      "Generating feature vectors\n",
      "Processing 43374/43374\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 40, 200)           18000200  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 40, 200)           0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128)               168448    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " activation (Activation)     (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18176969 (69.34 MB)\n",
      "Trainable params: 18176969 (69.34 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "305/305 [==============================] - ETA: 0s - loss: 0.4660 - accuracy: 0.7835\n",
      "Epoch 1: loss improved from inf to 0.46600, saving model to models/lstm-epoch_01-val-accuracy_0.853.hdf5\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "305/305 [==============================] - 56s 180ms/step - loss: 0.4660 - accuracy: 0.7835 - val_loss: 0.3497 - val_accuracy: 0.8534 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "305/305 [==============================] - ETA: 0s - loss: 0.3250 - accuracy: 0.8646\n",
      "Epoch 2: loss improved from 0.46600 to 0.32502, saving model to models/lstm-epoch_02-val-accuracy_0.882.hdf5\n",
      "305/305 [==============================] - 57s 187ms/step - loss: 0.3250 - accuracy: 0.8646 - val_loss: 0.3002 - val_accuracy: 0.8815 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "305/305 [==============================] - ETA: 0s - loss: 0.2574 - accuracy: 0.8937\n",
      "Epoch 3: loss improved from 0.32502 to 0.25740, saving model to models/lstm-epoch_03-val-accuracy_0.908.hdf5\n",
      "305/305 [==============================] - 51s 168ms/step - loss: 0.2574 - accuracy: 0.8937 - val_loss: 0.2303 - val_accuracy: 0.9076 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "305/305 [==============================] - ETA: 0s - loss: 0.2050 - accuracy: 0.9146\n",
      "Epoch 4: loss improved from 0.25740 to 0.20497, saving model to models/lstm-epoch_04-val-accuracy_0.916.hdf5\n",
      "305/305 [==============================] - 67s 219ms/step - loss: 0.2050 - accuracy: 0.9146 - val_loss: 0.1994 - val_accuracy: 0.9163 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "305/305 [==============================] - ETA: 0s - loss: 0.1683 - accuracy: 0.9272\n",
      "Epoch 5: loss improved from 0.20497 to 0.16833, saving model to models/lstm-epoch_05-val-accuracy_0.925.hdf5\n",
      "305/305 [==============================] - 68s 223ms/step - loss: 0.1683 - accuracy: 0.9272 - val_loss: 0.1827 - val_accuracy: 0.9246 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "!python3 src/lstm.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For testing using pretrained model\n",
    "For using pretrained model pass the path for pretrained best model as command line argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for GLOVE vectors\n",
      "Processing 1193514/0ng 103043/0ing 145919/0ing 187157/0cessing 194470/0cessing 365147/0cessing 746591/0709/0\n",
      "\n",
      "Found 14671 words in GLOVE\n",
      "Generating feature vectors\n",
      "Processing 43374/43374\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 40, 200)           18000200  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 40, 200)           0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128)               168448    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " activation (Activation)     (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18176969 (69.34 MB)\n",
      "Trainable params: 18176969 (69.34 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Generating feature vectors\n",
      "Processing 543/543\n",
      "\n",
      "5/5 [==============================] - 0s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "!python3 src/lstm.py 'models/lstm-epoch_05.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConvNets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for GLOVE seeds\n",
      "Processing 1193514/0essing 251215/0cessing 375164/0cessing 718305/0cessing 886112/0cessing 887877/0335/0100/0113/0\n",
      "\n",
      "Generating feature vectors\n",
      "Processing 43374/43374\n",
      "\n",
      "Epoch 1/8\n",
      "305/305 [==============================] - ETA: 0s - loss: 0.4717 - accuracy: 0.7658\n",
      "Epoch 1: loss improved from inf to 0.47170, saving model to models/4cnn-epoch_01.hdf5\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "305/305 [==============================] - 127s 416ms/step - loss: 0.4717 - accuracy: 0.7658 - val_loss: 0.3479 - val_accuracy: 0.8562 - lr: 0.0010\n",
      "Epoch 2/8\n",
      "305/305 [==============================] - ETA: 0s - loss: 0.3040 - accuracy: 0.8695\n",
      "Epoch 2: loss improved from 0.47170 to 0.30402, saving model to models/4cnn-epoch_02.hdf5\n",
      "305/305 [==============================] - 142s 465ms/step - loss: 0.3040 - accuracy: 0.8695 - val_loss: 0.2528 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 3/8\n",
      "305/305 [==============================] - ETA: 0s - loss: 0.2188 - accuracy: 0.9082\n",
      "Epoch 3: loss improved from 0.30402 to 0.21879, saving model to models/4cnn-epoch_03.hdf5\n",
      "305/305 [==============================] - 141s 463ms/step - loss: 0.2188 - accuracy: 0.9082 - val_loss: 0.2063 - val_accuracy: 0.9085 - lr: 0.0010\n",
      "Epoch 4/8\n",
      "305/305 [==============================] - ETA: 0s - loss: 0.1603 - accuracy: 0.9319\n",
      "Epoch 4: loss improved from 0.21879 to 0.16033, saving model to models/4cnn-epoch_04.hdf5\n",
      "305/305 [==============================] - 113s 371ms/step - loss: 0.1603 - accuracy: 0.9319 - val_loss: 0.1643 - val_accuracy: 0.9334 - lr: 0.0010\n",
      "Epoch 5/8\n",
      "305/305 [==============================] - ETA: 0s - loss: 0.1241 - accuracy: 0.9456\n",
      "Epoch 5: loss improved from 0.16033 to 0.12412, saving model to models/4cnn-epoch_05.hdf5\n",
      "305/305 [==============================] - 126s 414ms/step - loss: 0.1241 - accuracy: 0.9456 - val_loss: 0.1472 - val_accuracy: 0.9368 - lr: 0.0010\n",
      "Epoch 6/8\n",
      "144/305 [=============>................] - ETA: 1:01 - loss: 0.1028 - accuracy: 0.9533^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/revanth/Downloads/sentiment-analysis/src/cnn.py\", line 124, in <module>\n",
      "    model.fit(tweets, labels, batch_size=128, epochs=8, validation_split=0.1, shuffle=True, callbacks=[checkpoint, reduce_lr])\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1742, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 825, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 857, in _call\n",
      "    return self._no_variable_creation_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\", line 148, in __call__\n",
      "    return concrete_function._call_flat(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 1349, in _call_flat\n",
      "    return self._build_call_outputs(self._inference_function(*args))\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 196, in __call__\n",
      "    outputs = self._bound_context.call_function(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/context.py\", line 1457, in call_function\n",
      "    outputs = execute.execute(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python3 src/cnn.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For testing using pretrained model\n",
    "For using pretrained model pass the path for pretrained best model as command line argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for GLOVE seeds\n",
      "Processing 1193514/0ing 104684/0cessing 353678/0\n",
      "\n",
      "Generating feature vectors\n",
      "Processing 43374/43374\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 40, 200)           18000200  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 40, 200)           0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 38, 600)           360600    \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 36, 300)           540300    \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 34, 150)           135150    \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 32, 75)            33825     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2400)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 600)               1440600   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 600)               0         \n",
      "                                                                 \n",
      " activation (Activation)     (None, 600)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 601       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20511276 (78.24 MB)\n",
      "Trainable params: 20511276 (78.24 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Generating feature vectors\n",
      "Processing 543/543\n",
      "\n",
      "5/5 [==============================] - 0s 38ms/step\n"
     ]
    }
   ],
   "source": [
    "!python3 src/cnn.py \"models/4cnn-epoch_08.hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Majority Vote Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for GLOVE seeds\n",
      "Processing 1193514/0/0cessing 132219/0cessing 167167/0cessing 286962/0cessing 480290/0cessing 508237/0cessing 523274/0cessing 584339/0cessing 769745/0cessing 820640/0cessing 954705/0955048/0758/0675/0\n",
      "\n",
      "Generating feature vectors\n",
      "Processing 43374/4337423133/43374\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_input (InputLaye  [(None, 40)]              0         \n",
      " r)                                                              \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 40, 200)           18000200  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 40, 200)           0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 38, 600)           360600    \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 36, 300)           540300    \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 34, 150)           135150    \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 32, 75)            33825     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2400)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 600)               1440600   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 600)               0         \n",
      "                                                                 \n",
      " activation (Activation)     (None, 600)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20510675 (78.24 MB)\n",
      "Trainable params: 20510675 (78.24 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Generating feature vectors\n",
      "Processing 543/543\n",
      "\n",
      "1/1 [==============================] - 1s 581ms/step\n",
      "43/43 [==============================] - 30s 703ms/step\n"
     ]
    }
   ],
   "source": [
    "!python3 src/extract-cnn-feats.py \"models/4cnn-epoch_08.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39036, 600) (39036,) (4338, 600) (4338,)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "[LibLinear]....................................................................................................\n",
      "optimization finished, #iter = 1000\n",
      "\n",
      "WARNING: reaching max number of iterations\n",
      "Using -s 2 may be faster (also see FAQ)\n",
      "\n",
      "Objective value = -2859.107877\n",
      "nSV = 5195\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "LinearSVC(C=1, verbose=1)\n",
      "Val Accuracy: 96.75%\n"
     ]
    }
   ],
   "source": [
    "!python3 src/cnn-feats-svm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/revanth/Downloads/sentiment-analysis/src/majority-voting.py\", line 25, in <module>\n",
      "    main()\n",
      "  File \"/Users/revanth/Downloads/sentiment-analysis/src/majority-voting.py\", line 17, in main\n",
      "    predictions[range(NUM_PREDICTION_ROWS), current_preds] += 1\n",
      "IndexError: shape mismatch: indexing arrays could not be broadcast together with shapes (543,) (43374,) \n"
     ]
    }
   ],
   "source": [
    "!python3 src/majority-voting.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
